{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c0b313",
   "metadata": {},
   "source": [
    "![](https://media.istockphoto.com/vectors/many-arms-raised-of-diverse-and-multiethnic-people-holding-speech-vector-id1337786250?k=20&m=1337786250&s=612x612&w=0&h=zTFBr4VtORLSiWnRNCUTo0nbz4CEyHg8JW2w92E0tEU=)\n",
    "\n",
    "<br>\n",
    "\n",
    "# Portfolio Project: Language Detection\n",
    "\n",
    "<br>\n",
    "\n",
    "This project involves using Machine Learning to create a Language Detection Model to determine which language is which based on the data given.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "864f6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ade81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xemyc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3df83151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xx_sent_ud_sm\n",
    "nlp = xx_sent_ud_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "f99e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.zh import Chinese\n",
    "nlp_chinese = Chinese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "41fe89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudachipy import Dictionary, SplitMode\n",
    "tokenizer_obj = Dictionary().create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e745b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_greek = spacy.load(\"el_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ffd08",
   "metadata": {},
   "source": [
    "### Part 1: Web Scraping\n",
    "\n",
    "We need to gather the data that will be used for our model; therefore, we will need to web scrape as much data as we can. The plan is to scrape at least 1,000 sentences per language to allow our model to be more accurate when we test it. \n",
    "\n",
    "The languages that will be used for the `.csv` is: English, Spanish, French, German, Italian, Dutch, Portuguese, Chinese (simplified), Japanese, Korean, Russian, Hebrew, Arabic, Greek, Hindi, Armenian, Georgian, Latin, and Swedish. Each language will have at least 1,000 sentences or phrases, and no more than 1,200. To get the sentences in each language, we will be using a NLTK tokenizer.\n",
    "\n",
    "Because `nltk.tokenize` can only support English, Spanish, French, German, Italian, Dutch, Portuguese, Russian, and Swedish; `spacy` will be used for the rest of the languages. \n",
    "\n",
    "*Note: Chinese, Japanese, Greek, Hebrew, Armenian, Georgian, and Latin don't have enough data for the tokenizers to work properly. We will not be using them in our data, but I will continue to keep them is the `language_data.csv`, and will keep all the work I have done for them.\n",
    "Due to the nature of Chinese, we will be using data based on the characters/words rather than sentences. Also, for Chinese we will be using the [`jieba`](https://github.com/fxsjy/jieba) python dictionary, and for Japanese we will be using the [`sudachipy`](https://pypi.org/project/SudachiPy/0.2.1/) python dictionary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18619baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087\n"
     ]
    }
   ],
   "source": [
    "english_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1100:\n",
    "    for i in range(1):\n",
    "        webpage_en = requests.get('https://www.coolgenerator.com/random-sentence-generator')\n",
    "        soup_en = BeautifulSoup(webpage_en.content)\n",
    "        for sentence in soup_en.select(\".content > ul > li > p > b > span\"):\n",
    "            #print(sentence.text)\n",
    "            tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            for s in tokenized_sentence:\n",
    "                #print(s.strip())\n",
    "                english_sentences.append(s.strip())\n",
    "    x += 1\n",
    "    \n",
    "#print(english_sentences)\n",
    "print(len(english_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee66e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "spanish_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    webpage_sp = requests.get('http://www.smartphrase.com/cgi-bin/randomphrase.cgi?spanish&serious&normal')\n",
    "    soup_sp = BeautifulSoup(webpage_sp.content)\n",
    "    #print(soup_it.select(\"td\")[6])\n",
    "    #print(soup_it.select(\"tr\")[3].find_all('td'))\n",
    "\n",
    "    for sentence in soup_sp.find_all(attrs = {'bgcolor': '#DCDCFF'}):\n",
    "        if sentence.select(\"p\"):\n",
    "            new_sentence = sentence.text.replace(\".\", \". \").replace(\"?\", \"? \").replace(\"!\", \"! \")\n",
    "            #print(new_sentence)\n",
    "            tokenized_sentence = sent_tokenize(new_sentence)\n",
    "            #print(tokenized_sentence[0].strip())\n",
    "            spanish_sentences.append(tokenized_sentence[0].strip())\n",
    "        \n",
    "            #this was removing the punctuation\n",
    "            #new_sentence = re.split(r\"[.!?]+\", sentence.text.strip())\n",
    "            #print(new_sentence[0])\n",
    "    x += 1\n",
    "    \n",
    "#print(spanish_sentences)\n",
    "print(len(spanish_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bf22c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "french_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    webpage_fr = requests.get('http://www.smartphrase.com/cgi-bin/randomphrase.cgi?french&serious&normal')\n",
    "    soup_fr = BeautifulSoup(webpage_fr.content)\n",
    "    #print(soup_it.select(\"td\")[6])\n",
    "    #print(soup_it.select(\"tr\")[3].find_all('td'))\n",
    "\n",
    "    for sentence in soup_fr.find_all(attrs = {'bgcolor': '#DCDCFF'}):\n",
    "        if sentence.select(\"p\"):\n",
    "            new_sentence = sentence.text.replace(\".\", \". \").replace(\"?\", \"? \").replace(\"!\", \"! \")\n",
    "            #print(new_sentence)\n",
    "            tokenized_sentence = sent_tokenize(new_sentence)\n",
    "            #print(tokenized_sentence[0].strip())\n",
    "            french_sentences.append(tokenized_sentence[0].strip())\n",
    "        \n",
    "            #this was removing the punctuation\n",
    "            #new_sentence = re.split(r\"[.!?]+\", sentence.text.strip())\n",
    "            #print(new_sentence[0])\n",
    "    x += 1\n",
    "    \n",
    "#print(french_sentences)\n",
    "print(len(french_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62bc2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "german_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    webpage_de = requests.get('http://www.smartphrase.com/cgi-bin/randomphrase.cgi?german&serious&normal')\n",
    "    soup_de = BeautifulSoup(webpage_de.content)\n",
    "    #print(soup_it.select(\"td\")[6])\n",
    "    #print(soup_it.select(\"tr\")[3].find_all('td'))\n",
    "\n",
    "    for sentence in soup_de.find_all(attrs = {'bgcolor': '#DCDCFF'}):\n",
    "        if sentence.select(\"p\"):\n",
    "            new_sentence = sentence.text.replace(\".\", \". \").replace(\"?\", \"? \").replace(\"!\", \"! \")\n",
    "            #print(new_sentence)\n",
    "            tokenized_sentence = sent_tokenize(new_sentence)\n",
    "            #print(tokenized_sentence[0].strip())\n",
    "            german_sentences.append(tokenized_sentence[0].strip())\n",
    "        \n",
    "            #this was removing the punctuation\n",
    "            #new_sentence = re.split(r\"[.!?]+\", sentence.text.strip())\n",
    "            #print(new_sentence[0])\n",
    "    x += 1\n",
    "    \n",
    "#print(german_sentences)\n",
    "print(len(german_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e18bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "italian_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    webpage_it = requests.get('http://www.smartphrase.com/cgi-bin/randomphrase.cgi?italian&serious&normal&229&&&&&')\n",
    "    soup_it = BeautifulSoup(webpage_it.content)\n",
    "    #print(soup_it.select(\"td\")[6])\n",
    "    #print(soup_it.select(\"tr\")[3].find_all('td'))\n",
    "\n",
    "    for sentence in soup_it.find_all(attrs = {'bgcolor': '#DCDCFF'}):\n",
    "        if sentence.select(\"p\"):\n",
    "            new_sentence = sentence.text.replace(\".\", \". \").replace(\"?\", \"? \").replace(\"!\", \"! \")\n",
    "            #print(new_sentence)\n",
    "            tokenized_sentence = sent_tokenize(new_sentence)\n",
    "            #print(tokenized_sentence[0].strip())\n",
    "            italian_sentences.append(tokenized_sentence[0].strip())\n",
    "        \n",
    "            #this was removing the punctuation\n",
    "            #new_sentence = re.split(r\"[.!?]+\", sentence.text.strip())\n",
    "            #print(new_sentence[0])\n",
    "    x += 1\n",
    "    \n",
    "#print(italian_sentences)\n",
    "print(len(italian_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3080611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "dutch_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    webpage_du = requests.get('http://www.smartphrase.com/cgi-bin/randomphrase.cgi?dutch&serious&normal')\n",
    "    soup_du = BeautifulSoup(webpage_du.content)\n",
    "    #print(soup_it.select(\"td\")[6])\n",
    "    #print(soup_it.select(\"tr\")[3].find_all('td'))\n",
    "\n",
    "    for sentence in soup_du.find_all(attrs = {'bgcolor': '#DCDCFF'}):\n",
    "        if sentence.select(\"p\"):\n",
    "            new_sentence = sentence.text.replace(\".\", \". \").replace(\"?\", \"? \").replace(\"!\", \"! \")\n",
    "            #print(new_sentence)\n",
    "            tokenized_sentence = sent_tokenize(new_sentence)\n",
    "            #print(tokenized_sentence[0].strip())\n",
    "            dutch_sentences.append(tokenized_sentence[0].strip())\n",
    "    x += 1\n",
    "    \n",
    "#print(dutch_sentences)\n",
    "print(len(dutch_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf1b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "portuguese_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    webpage_pt = requests.get('http://www.smartphrase.com/cgi-bin/randomphrase.cgi?portuguese&humorous&normal')\n",
    "    soup_pt = BeautifulSoup(webpage_pt.content)\n",
    "    #print(soup_it.select(\"td\")[6])\n",
    "    #print(soup_it.select(\"tr\")[3].find_all('td'))\n",
    "\n",
    "    for sentence in soup_pt.find_all(attrs = {'bgcolor': '#DCDCFF'}):\n",
    "        if sentence.select(\"p\"):\n",
    "            new_sentence = sentence.text.replace(\".\", \". \").replace(\"?\", \"? \").replace(\"!\", \"! \")\n",
    "            #print(new_sentence)\n",
    "            tokenized_sentence = sent_tokenize(new_sentence)\n",
    "            #print(tokenized_sentence[0].strip())\n",
    "            portuguese_sentences.append(tokenized_sentence[0].strip())\n",
    "    x += 1\n",
    "    \n",
    "#print(portuguese_sentences)\n",
    "print(len(portuguese_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "516cffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n"
     ]
    }
   ],
   "source": [
    "chinese_words = []\n",
    "\n",
    "x = 0\n",
    "while x < 1:\n",
    "    for i in range(1):\n",
    "        webpage_zh = requests.get('https://generator.lorem-ipsum.info/_chinese')\n",
    "        soup_zh = BeautifulSoup(webpage_zh.content)\n",
    "\n",
    "        for sentence in soup_zh.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp_chinese(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                chinese_words.append(s)\n",
    "                if len(chinese_words) == 1099:\n",
    "                    break\n",
    "\n",
    "    x += 1\n",
    "    \n",
    "print(len(chinese_words))\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "#simplified chinese\n",
    "#chinese_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 11:\n",
    "    #for i in range(1):\n",
    "        #webpage_zh = requests.get('https://generator.lorem-ipsum.info/_chinese')\n",
    "        #soup_zh = BeautifulSoup(webpage_zh.content)\n",
    "        #print(soup_zh.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_zh.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            #for s in tokenized_sentence:\n",
    "                #s = s.split(\"。\")\n",
    "                #for i in s:\n",
    "                    #print(i.strip())\n",
    "                    #chinese_sentences.append(i.strip())\n",
    "    #x += 1\n",
    "    \n",
    "#print(chinese_sentences)\n",
    "#print(len(chinese_sentences))\n",
    "\n",
    "\n",
    "#---------------------------------------\n",
    "\n",
    "\n",
    "#practice = []\n",
    "#tokenized_sentence = jieba.tokenize(u'我喜欢放学后学习数学')\n",
    "#for s in tokenized_sentence:\n",
    "    #print(s[0])\n",
    "    #practice.append(s[0])\n",
    "    \n",
    "#print(practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "fd8942a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "japanese_words = []\n",
    "\n",
    "x = 0\n",
    "while x < 1000:\n",
    "    for i in range(1):\n",
    "        webpage_jp = requests.get('https://generator.lorem-ipsum.info/_japanese2')\n",
    "        soup_jp = BeautifulSoup(webpage_jp.content)\n",
    "        #print(soup_jp.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_jp.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = tokenizer_obj.tokenize(sentence.text)\n",
    "            #print(tokenized_sentence)\n",
    "            japanese_words.append(tokenized_sentence)\n",
    "            \n",
    "    x += 1\n",
    "    \n",
    "#print(japanese_sentences)\n",
    "print(len(japanese_words))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#japanese_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 32:\n",
    "    #for i in range(1):\n",
    "        #webpage_jp = requests.get('https://generator.lorem-ipsum.info/_japanese2')\n",
    "        #soup_jp = BeautifulSoup(webpage_jp.content)\n",
    "        #print(soup_jp.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_jp.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            #for s in tokenized_sentence:\n",
    "                #s = s.split(\"。\")\n",
    "                #for i in s:\n",
    "                    #print(i.strip())\n",
    "                    #japanese_sentences.append(i.strip())\n",
    "    #x += 1\n",
    "    \n",
    "#print(japanese_sentences)\n",
    "#print(len(japanese_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a9d789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n"
     ]
    }
   ],
   "source": [
    "korean_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 17:\n",
    "    for i in range(1):\n",
    "        webpage_ko = requests.get('https://generator.lorem-ipsum.info/_korean2')\n",
    "        soup_ko = BeautifulSoup(webpage_ko.content)\n",
    "        #print(soup_ko.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_ko.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(str(s).strip())\n",
    "                korean_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "#print(korean_sentences)\n",
    "#for s in korean_sentences:\n",
    "    #print(s)\n",
    "\n",
    "print(len(korean_sentences))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#korean_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 15:\n",
    "    #for i in range(1):\n",
    "        #webpage_ko = requests.get('https://generator.lorem-ipsum.info/_korean2')\n",
    "        #soup_ko = BeautifulSoup(webpage_ko.content)\n",
    "        #print(soup_ko.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_ko.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            #for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                #korean_sentences.append(s.strip())\n",
    "    #x += 1\n",
    "    \n",
    "#print(korean_sentences)\n",
    "#print(len(korean_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d3aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177\n"
     ]
    }
   ],
   "source": [
    "russian_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 870:\n",
    "    for i in range(1):\n",
    "        webpage_ru = requests.get('https://www.coolgenerator.com/random-sentence-generator?lang=ru')\n",
    "        soup_ru = BeautifulSoup(webpage_ru.content)\n",
    "        for sentence in soup_ru.select(\".content > ul > li > p > b > span\"):\n",
    "            #print(sentence.text)\n",
    "            tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            for s in tokenized_sentence:\n",
    "                #print(s.strip())\n",
    "                russian_sentences.append(s.strip())\n",
    "    x += 1\n",
    "    \n",
    "#print(russian_sentences)\n",
    "print(len(russian_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da6e54f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\n"
     ]
    }
   ],
   "source": [
    "hebrew_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 24:\n",
    "    for i in range(1):\n",
    "        webpage_he = requests.get('https://generator.lorem-ipsum.info/_hebrew')\n",
    "        soup_he = BeautifulSoup(webpage_he.content)\n",
    "        #print(soup_he.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_he.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(s)\n",
    "                hebrew_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "#print(hebrew_sentences)\n",
    "print(len(hebrew_sentences))\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "#hebrew_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 20:\n",
    "    #for i in range(1):\n",
    "        #webpage_he = requests.get('https://generator.lorem-ipsum.info/_hebrew')\n",
    "        #soup_he = BeautifulSoup(webpage_he.content)\n",
    "        #print(soup_he.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_he.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            #for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                #hebrew_sentences.append(s)\n",
    "    #x += 1\n",
    "    \n",
    "#print(hebrew_sentences)\n",
    "#print(len(hebrew_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce1b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n"
     ]
    }
   ],
   "source": [
    "arabic_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 25:\n",
    "    for i in range(1):\n",
    "        webpage_arb = requests.get('https://generator.lorem-ipsum.info/_arabic')\n",
    "        soup_arb = BeautifulSoup(webpage_arb.content)\n",
    "        #print(soup_arb.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_arb.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(s)\n",
    "                arabic_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "#print(arabic_sentences)\n",
    "print(len(arabic_sentences))\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#arabic_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 20:\n",
    "    #for i in range(1):\n",
    "        #webpage_arb = requests.get('https://generator.lorem-ipsum.info/_arabic')\n",
    "        #soup_arb = BeautifulSoup(webpage_arb.content)\n",
    "        #print(soup_arb.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_arb.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                #arabic_sentences.append(s)\n",
    "    #x += 1\n",
    "    \n",
    "#print(arabic_sentences)\n",
    "#print(len(arabic_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40369eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018\n"
     ]
    }
   ],
   "source": [
    "hindi_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 485:\n",
    "    for i in range(1):\n",
    "        webpage_hi = requests.get('https://generator.lorem-ipsum.info/_hindi')\n",
    "        soup_hi = BeautifulSoup(webpage_hi.content)\n",
    "        #print(soup_hi.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_hi.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(str(s).strip())\n",
    "                hindi_sentences.append(s)\n",
    "                    \n",
    "    x += 1\n",
    "    \n",
    "#print(hindi_sentences)\n",
    "print(len(hindi_sentences))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#hindi_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 100:\n",
    "    #for i in range(1):\n",
    "        #webpage_hi = requests.get('https://generator.lorem-ipsum.info/_hindi')\n",
    "        #soup_hi = BeautifulSoup(webpage_hi.content)\n",
    "        #print(soup_hi.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_hi.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #for s in tokenized_sentence:\n",
    "                #s = s.split(\"\\n\\n\")\n",
    "                #for i in s:\n",
    "                    #print(i.strip())\n",
    "                    #hindi_sentences.append(i.strip())\n",
    "    #x += 1\n",
    "    \n",
    "#print(hindi_sentences)\n",
    "#print(len(hindi_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58a1839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "greek_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 18:\n",
    "    for i in range(1):\n",
    "        webpage_gr = requests.get('https://generator.lorem-ipsum.info/_greek')\n",
    "        soup_gr = BeautifulSoup(webpage_gr.content)\n",
    "        #print(soup_gr.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_gr.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp_greek(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(s)\n",
    "                greek_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "#print(greek_sentences)\n",
    "print(len(greek_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19857768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091\n"
     ]
    }
   ],
   "source": [
    "armenian_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 700:\n",
    "    for i in range(1):\n",
    "        webpage_arm = requests.get('https://generator.lorem-ipsum.info/_armenian')\n",
    "        soup_arm = BeautifulSoup(webpage_arm.content)\n",
    "        #print(soup_arm.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_arm.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(s)\n",
    "                armenian_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "#print(armenian_sentences)\n",
    "print(len(armenian_sentences))\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#armenian_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 20:\n",
    "    #for i in range(1):\n",
    "        #webpage_arm = requests.get('https://generator.lorem-ipsum.info/_armenian')\n",
    "        #soup_arm = BeautifulSoup(webpage_arm.content)\n",
    "        #print(soup_arm.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_arm.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                #armenian_sentences.append(s)\n",
    "    #x += 1\n",
    "    \n",
    "#print(armenian_sentences)\n",
    "#print(len(armenian_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703e0734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025\n"
     ]
    }
   ],
   "source": [
    "georgian_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 890:\n",
    "    for i in range(1):\n",
    "        webpage_kt = requests.get('https://generator.lorem-ipsum.info/_georgian')\n",
    "        soup_kt = BeautifulSoup(webpage_kt.content)\n",
    "        #print(soup_kt.select(\"#txtDiv\"))\n",
    "\n",
    "        for sentence in soup_kt.select(\"#txtDiv\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(s)\n",
    "                georgian_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "#print(georgian_sentences)\n",
    "print(len(georgian_sentences))\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "#georgian_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 20:\n",
    "    #for i in range(1):\n",
    "        #webpage_kt = requests.get('https://generator.lorem-ipsum.info/_georgian')\n",
    "        #soup_kt = BeautifulSoup(webpage_kt.content)\n",
    "        #print(soup_kt.select(\"#txtDiv\"))\n",
    "\n",
    "        #for sentence in soup_kt.select(\"#txtDiv\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                #georgian_sentences.append(s)\n",
    "    #x += 1\n",
    "    \n",
    "#print(georgian_sentences)\n",
    "#print(len(georgian_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3bcffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n"
     ]
    }
   ],
   "source": [
    "latin_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 18:\n",
    "    for i in range(1):\n",
    "        webpage_lat = requests.get('https://www.lipsum.com/feed/html')\n",
    "        soup_lat = BeautifulSoup(webpage_lat.content)\n",
    "        #print(soup_lat.select(\"#lipsum\"))\n",
    "        for sentence in soup_lat.select(\"#lipsum\"):\n",
    "            tokenized_sentence = nlp(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #print(len(tokenized_sentence))\n",
    "            for s in tokenized_sentence.sents:\n",
    "                #print(s)\n",
    "                latin_sentences.append(s)\n",
    "    x += 1\n",
    "    \n",
    "print(len(latin_sentences))\n",
    "#print(latin_sentences)\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#latin_sentences = []\n",
    "\n",
    "#x = 0\n",
    "#while x < 18:\n",
    "    #for i in range(1):\n",
    "        #webpage_lat = requests.get('https://www.lipsum.com/feed/html')\n",
    "        #soup_lat = BeautifulSoup(webpage_lat.content)\n",
    "        #print(soup_lat.select(\"#lipsum\"))\n",
    "        #for sentence in soup_lat.select(\"#lipsum\"):\n",
    "            #tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            #for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                #latin_sentences.append(s)\n",
    "    #x += 1\n",
    "    \n",
    "#print(len(latin_sentences))\n",
    "#print(latin_sentences)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "#This code works, the webpage just takes too long to load the data\n",
    "\n",
    "#x = 0\n",
    "#while x < 1000:\n",
    "    #for i in range(1):\n",
    "        #webpage_lat = requests.get('https://corpora.fi.muni.cz/cblm/generate.cgi?language=latin')\n",
    "        #soup_lat = BeautifulSoup(webpage_lat.content)\n",
    "        #print(soup_lat)\n",
    "        #for sentence in soup_lat.select(\".g\"):\n",
    "            #print(sentence.text.strip())\n",
    "            #latin_sentences.append(sentence.text.strip())\n",
    "    #x += 1\n",
    "    \n",
    "#print(latin_sentences)\n",
    "#print(len(latin_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cded86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n"
     ]
    }
   ],
   "source": [
    "swedish_sentences = []\n",
    "\n",
    "x = 0\n",
    "while x < 43:\n",
    "    for i in range(1):\n",
    "        webpage_sw = requests.get('http://xn--lkss-soa3h.vogelius.se/l%C3%A4ngre.php')\n",
    "        soup_sw = BeautifulSoup(webpage_sw.content)\n",
    "        #print(soup_sw.select(\".lI\"))\n",
    "        for sentence in soup_sw.select('.lI'):\n",
    "            tokenized_sentence = sent_tokenize(sentence.text.strip())\n",
    "            #print(tokenized_sentence)\n",
    "            for s in tokenized_sentence:\n",
    "                #print(s)\n",
    "                swedish_sentences.append(s)\n",
    "    x += 1\n",
    "        \n",
    "print(len(swedish_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314bda4e",
   "metadata": {},
   "source": [
    "Data was gathered from the following:\n",
    "- [Cool Generator (English, Russian)](https://www.coolgenerator.com/random-sentence-generator)\n",
    "- [SmartPhrase.com Online Phrasebook (Spanish, German, French, Italian, Dutch, Portuguese)](http://www.smartphrase.com/index.shtml)\n",
    "- [Professional lorem ipsum generator (Chinese, Japanese, Korean, Hebrew, Arabic, Greek, Hindi, Armenian, Georgian)](https://generator.lorem-ipsum.info/)\n",
    "- [Lorem Ipsum (Latin)](https://www.lipsum.com/feed/html)\n",
    "- [LÖKSÅS IPSUM (Swedish)](http://xn--lkss-soa3h.vogelius.se/l%C3%A4ngre.php)\n",
    "\n",
    "*Note: The lorem ipsum generators follows the grammar & sentence structures of these languages, but it doesn't make any sense. Transliterations are in Greek, Armenian, Georgian*\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b82e3",
   "metadata": {},
   "source": [
    "### Part 2: Create and Combine DataFrames\n",
    "\n",
    "After getting the randomized sentences for each language, and putting them into separate language lists, we can now use the lists and create DataFrames from each of them. We will create a `text` column that will contain the phrases and sentences; and we also need to put a `language` column to differentiate which language is which because we will be combining all the DataFrames into one large DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f1deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "english = pd.DataFrame(english_sentences, columns = ['text'])\n",
    "#english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1adc084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Indeed, we tend to have less Neanderthal DNA n...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>The International Academy of Digital Arts and ...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Tom doesn't like basketball much, but he reall...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Chamber of Commerce offered Facebook the chanc...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Not understanding it?</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "1082  Indeed, we tend to have less Neanderthal DNA n...  english\n",
       "1083  The International Academy of Digital Arts and ...  english\n",
       "1084  Tom doesn't like basketball much, but he reall...  english\n",
       "1085  Chamber of Commerce offered Facebook the chanc...  english\n",
       "1086                              Not understanding it?  english"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english['language'] = ['english'] * len(english) \n",
    "english.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae587808",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish = pd.DataFrame(spanish_sentences, columns = ['text'])\n",
    "#spanish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4c8cbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>¿Queréis ir al cine?</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>¿Ha ya el tren de onze y cuarto llegado?</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Prefiero jugar al tenis.</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>¿Dónde estan los servicios / las duchas?</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Tengo una reserva para Johnson.</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text language\n",
       "995                      ¿Queréis ir al cine?  spanish\n",
       "996  ¿Ha ya el tren de onze y cuarto llegado?  spanish\n",
       "997                  Prefiero jugar al tenis.  spanish\n",
       "998  ¿Dónde estan los servicios / las duchas?  spanish\n",
       "999           Tengo una reserva para Johnson.  spanish"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish['language'] = ['spanish'] * len(spanish)\n",
    "spanish.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6445a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "french = pd.DataFrame(french_sentences, columns = ['text'])\n",
    "#french.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35c4f9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Le train part a quel quai?</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Voulez-vous répéter cela, s'il vous plaît.</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>C'est le premier fois que je téléphone en France.</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Cette place est occupée.</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Où est la boulangerie?</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text language\n",
       "995                         Le train part a quel quai?   french\n",
       "996         Voulez-vous répéter cela, s'il vous plaît.   french\n",
       "997  C'est le premier fois que je téléphone en France.   french\n",
       "998                           Cette place est occupée.   french\n",
       "999                             Où est la boulangerie?   french"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french['language'] = ['french'] * len(french)\n",
    "french.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd9a2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "german = pd.DataFrame(german_sentences, columns = ['text'])\n",
    "#german.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3804b77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Ein Fahrschein-Heft bitte.</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Um welche Zeit macht die Bank auf?</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Was bedeutet das?</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Drei Briefmarken für je 1 Mark bitte.</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Dieser Platz ist besetzt.</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text language\n",
       "995             Ein Fahrschein-Heft bitte.   german\n",
       "996     Um welche Zeit macht die Bank auf?   german\n",
       "997                      Was bedeutet das?   german\n",
       "998  Drei Briefmarken für je 1 Mark bitte.   german\n",
       "999              Dieser Platz ist besetzt.   german"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german['language'] = ['german'] * len(german)\n",
    "german.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70d63a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "italian = pd.DataFrame(italian_sentences, columns = ['text'])\n",
    "#italian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85c34c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Quanto dura il viaggio?</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>C'è un negozio nel campeggio?</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Dov'è il duty free?</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Il suo nome e' Rebecca.</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>La batteria è scarica.</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text language\n",
       "995        Quanto dura il viaggio?  italian\n",
       "996  C'è un negozio nel campeggio?  italian\n",
       "997            Dov'è il duty free?  italian\n",
       "998        Il suo nome e' Rebecca.  italian\n",
       "999         La batteria è scarica.  italian"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "italian['language'] = ['italian'] * len(italian)\n",
    "italian.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8b83087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch = pd.DataFrame(dutch_sentences, columns = ['text'])\n",
    "#dutch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cb2707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Retour Hoogeveen, alstublieft.</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Retour Hoogeveen, alstublieft.</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Deze weg volgen.</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Alstublieft controleer de accu / batterij.</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Heb je ruimte voor een caravan?</td>\n",
       "      <td>dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text language\n",
       "995              Retour Hoogeveen, alstublieft.    dutch\n",
       "996              Retour Hoogeveen, alstublieft.    dutch\n",
       "997                            Deze weg volgen.    dutch\n",
       "998  Alstublieft controleer de accu / batterij.    dutch\n",
       "999             Heb je ruimte voor een caravan?    dutch"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch['language'] = ['dutch'] * len(dutch)\n",
    "dutch.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48696907",
   "metadata": {},
   "outputs": [],
   "source": [
    "portuguese = pd.DataFrame(portuguese_sentences, columns = ['text'])\n",
    "#portuguese.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59b48b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Desculpe, importa-se que o contemple durante u...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Gostarias de ir a minha casa e fazer as coisas...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Não são permitidos elefantes no bar depois das...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Desculpe, importa-se que o contemple durante u...</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Chama a isso uma sanduíche de fiambre?</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    language\n",
       "995  Desculpe, importa-se que o contemple durante u...  portuguese\n",
       "996  Gostarias de ir a minha casa e fazer as coisas...  portuguese\n",
       "997  Não são permitidos elefantes no bar depois das...  portuguese\n",
       "998  Desculpe, importa-se que o contemple durante u...  portuguese\n",
       "999             Chama a isso uma sanduíche de fiambre?  portuguese"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portuguese['language'] = ['portuguese'] * len(portuguese)\n",
    "portuguese.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "20131548",
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = pd.DataFrame(chinese_words, columns = ['text'])\n",
    "#chinese.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "f41fb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = chinese.loc[chinese['text'] != '。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7975f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>説</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>望</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>支</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>千</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>藻</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text language\n",
       "1094    説  chinese\n",
       "1095    望  chinese\n",
       "1096    支  chinese\n",
       "1097    千  chinese\n",
       "1098    藻  chinese"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese['language'] = ['chinese'] * len(chinese)\n",
    "chinese.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "5557a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese = pd.DataFrame(list(zip(japanese_words)), columns = ['text'])\n",
    "#japanese.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "164fadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>( , え, 擢留, 尾屋, る, ほ, きえ, 阿舳, 樹以, 野, 以, 模, 素, リ...</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>( , ん, さ, ゃ, 、, いる, きれ, そ, さす, 無, 以, ゆ, よよ, ね,...</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>( , ら, 毛, ゅ, ゃ, け, 、, に, み, ゅ, し, 、, し, た, 、, ...</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>( , 個, 保, そ, にっ, 樹, ゃ, うい, 名尾, す, 巣瀬, 区, お, て,...</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>( , 都, 個, 。, れれ, と, ゃ, てらう, つ, 、, 二樹, 御, 氏尾, め...</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  language\n",
       "995  ( , え, 擢留, 尾屋, る, ほ, きえ, 阿舳, 樹以, 野, 以, 模, 素, リ...  japanese\n",
       "996  ( , ん, さ, ゃ, 、, いる, きれ, そ, さす, 無, 以, ゆ, よよ, ね,...  japanese\n",
       "997  ( , ら, 毛, ゅ, ゃ, け, 、, に, み, ゅ, し, 、, し, た, 、, ...  japanese\n",
       "998  ( , 個, 保, そ, にっ, 樹, ゃ, うい, 名尾, す, 巣瀬, 区, お, て,...  japanese\n",
       "999  ( , 都, 個, 。, れれ, と, ゃ, てらう, つ, 、, 二樹, 御, 氏尾, め...  japanese"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japanese['language'] = ['japanese'] * len(japanese)\n",
    "japanese.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69748518",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean = pd.DataFrame({'text': korean_sentences})\n",
    "#korean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53a324ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>(없는, 얼음, 기쁘며, .)</td>\n",
       "      <td>korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>(천하를, 찾아다녀도, ,, 청춘이, 우리, 싶이, 있다, .)</td>\n",
       "      <td>korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>(보내는, 칼이다, .)</td>\n",
       "      <td>korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>(가진, 청춘, 얼마나, 칼이다, .)</td>\n",
       "      <td>korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>(앞이, 품에, 끝까지, 인생을, 스며들어, 자신과, 있다, .)</td>\n",
       "      <td>korean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text language\n",
       "1023                      (없는, 얼음, 기쁘며, .)   korean\n",
       "1024   (천하를, 찾아다녀도, ,, 청춘이, 우리, 싶이, 있다, .)   korean\n",
       "1025                         (보내는, 칼이다, .)   korean\n",
       "1026                 (가진, 청춘, 얼마나, 칼이다, .)   korean\n",
       "1027  (앞이, 품에, 끝까지, 인생을, 스며들어, 자신과, 있다, .)   korean"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korean['language'] = ['korean'] * len(korean)\n",
    "korean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a333beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian = pd.DataFrame(russian_sentences, columns = ['text'])\n",
    "#russian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c21d03b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Он говорит, женщина, а Марья Николаевна - барыня.</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>Выдающаяся московская барыня и хозяйка подмоск...</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>И не говорите как барыня.</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Да?</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Если барыня спросит, я буду в своей комнате.</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "1172  Он говорит, женщина, а Марья Николаевна - барыня.  russian\n",
       "1173  Выдающаяся московская барыня и хозяйка подмоск...  russian\n",
       "1174                          И не говорите как барыня.  russian\n",
       "1175                                                Да?  russian\n",
       "1176       Если барыня спросит, я буду в своей комнате.  russian"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian['language'] = ['russian'] * len(russian)\n",
    "russian.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d477b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hebrew = pd.DataFrame(list(zip(hebrew_sentences)), columns = ['text'])\n",
    "#hebrew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f7eed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(ויקי, מוסיקה, וספציפיים, אם, עוד, ,, אם, היא,...</td>\n",
       "      <td>hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(רבה, למנוע, פוליטיקה, אל, ,, אל, יסוד, ערבית,...</td>\n",
       "      <td>hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(אם, שתי, קסאם, סטטיסטיקה, ,, גם, אחר, הראשי, ...</td>\n",
       "      <td>hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>(כלל, מבוקשים, לויקיפדיה, גם, ,, תחבורה, ותשוב...</td>\n",
       "      <td>hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>(מלא, את, שונה, רביעי, הגולשות, ,, סדר, דת, הנ...</td>\n",
       "      <td>hebrew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "997   (ויקי, מוסיקה, וספציפיים, אם, עוד, ,, אם, היא,...   hebrew\n",
       "998   (רבה, למנוע, פוליטיקה, אל, ,, אל, יסוד, ערבית,...   hebrew\n",
       "999   (אם, שתי, קסאם, סטטיסטיקה, ,, גם, אחר, הראשי, ...   hebrew\n",
       "1000  (כלל, מבוקשים, לויקיפדיה, גם, ,, תחבורה, ותשוב...   hebrew\n",
       "1001  (מלא, את, שונה, רביעי, הגולשות, ,, סדר, דת, הנ...   hebrew"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebrew['language'] = ['hebrew'] * len(hebrew)\n",
    "hebrew.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d28361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic = pd.DataFrame(list(zip(arabic_sentences)), columns = ['text'])\n",
    "#arabic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bace4850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>(فكان, أسيا, وجهان, في, جهة, ,, الجو, بالرغم, ...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>(بالحرب, الأعمال, وفي, إذ, ,, شعار, إيطاليا, م...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>(لعدم, اتفاقية, الحكومة, ذلك, ان, .)</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>(أم, حين, فمرّ, لعملة, ,, الصفحة, بالحرب, الشه...</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>(أن, قام, العالم, الدنمارك, .)</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "1033  (فكان, أسيا, وجهان, في, جهة, ,, الجو, بالرغم, ...   arabic\n",
       "1034  (بالحرب, الأعمال, وفي, إذ, ,, شعار, إيطاليا, م...   arabic\n",
       "1035               (لعدم, اتفاقية, الحكومة, ذلك, ان, .)   arabic\n",
       "1036  (أم, حين, فمرّ, لعملة, ,, الصفحة, بالحرب, الشه...   arabic\n",
       "1037                     (أن, قام, العالم, الدنمارك, .)   arabic"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic['language'] = ['arabic'] * len(arabic)\n",
    "arabic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66aef34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = pd.DataFrame(list(zip(hindi_sentences)), columns = ['text'])\n",
    "#hindi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45ce695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>(परिभाषित, केन्द्रित, यन्त्रालय, देने, चुनने, ...</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>(कोहम, तकरीबन, ऎसाजीस, स्थापित, दौरान, ध्वनि, ...</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>(भेदनक्षमता, मार्गदर्शन, डाले, ।, उशकी, देकर, ...</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>(सहयोग, तकनीकी, जानकारी, कम्प्युटर, भाषा, बनान...</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>(समजते, नाकर, द्वारा, निरपेक्ष, विचारशिलता, मु...</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "1013  (परिभाषित, केन्द्रित, यन्त्रालय, देने, चुनने, ...    hindi\n",
       "1014  (कोहम, तकरीबन, ऎसाजीस, स्थापित, दौरान, ध्वनि, ...    hindi\n",
       "1015  (भेदनक्षमता, मार्गदर्शन, डाले, ।, उशकी, देकर, ...    hindi\n",
       "1016  (सहयोग, तकनीकी, जानकारी, कम्प्युटर, भाषा, बनान...    hindi\n",
       "1017  (समजते, नाकर, द्वारा, निरपेक्ष, विचारशिलता, मु...    hindi"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi['language'] = ['hindi'] * len(hindi)\n",
    "hindi.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ad41da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek = pd.DataFrame(list(zip(greek_sentences)), columns = ['text'])\n",
    "#greek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5504810b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(Εθμ, ιλλθδ, περσεqθερισ, εξ, ,, πρι, μοδο, φα...</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(Vιταε, γραεcι, σεα, αδ, ,, τε, ηισ, μθcιθσ, ι...</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(\\n\\n, Εα, νεc, μαγνα, αππελλαντθρ, ,, εοσ, πρ...</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(Ναμ, cθ, αβηορρεαντ, ομιτταντθρ, .)</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>(Πρι, ποπθλο, cονστιτθτο, εθ, ,, ιδ, εοσ, φαcε...</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "996   (Εθμ, ιλλθδ, περσεqθερισ, εξ, ,, πρι, μοδο, φα...    greek\n",
       "997   (Vιταε, γραεcι, σεα, αδ, ,, τε, ηισ, μθcιθσ, ι...    greek\n",
       "998   (\\n\\n, Εα, νεc, μαγνα, αππελλαντθρ, ,, εοσ, πρ...    greek\n",
       "999                (Ναμ, cθ, αβηορρεαντ, ομιτταντθρ, .)    greek\n",
       "1000  (Πρι, ποπθλο, cονστιτθτο, εθ, ,, ιδ, εοσ, φαcε...    greek"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greek['language'] = ['greek'] * len(greek)\n",
    "greek.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df70d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "armenian = pd.DataFrame(list(zip(armenian_sentences)), columns = ['text'])\n",
    "#armenian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b933c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>(թե, վիդիսսե, պեռպեթուա, մել, ,, ութ, եամ, նոն...</td>\n",
       "      <td>armenian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>(սինթ, ածծումսան, սադիպսծինգ, ծում, նո, ,, մեա...</td>\n",
       "      <td>armenian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>(լոռեմ, իպսում, դոլոռ, սիթ, ամեթ, ,, եխ, իուս,...</td>\n",
       "      <td>armenian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>(թե, գռաեծե, վեռեառ, գռաեծիս, քուի, ,, դեբեթ, ...</td>\n",
       "      <td>armenian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>(լոռեմ, իպսում, դոլոռ, սիթ, ամեթ, ,, նո, վել, ...</td>\n",
       "      <td>armenian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  language\n",
       "1086  (թե, վիդիսսե, պեռպեթուա, մել, ,, ութ, եամ, նոն...  armenian\n",
       "1087  (սինթ, ածծումսան, սադիպսծինգ, ծում, նո, ,, մեա...  armenian\n",
       "1088  (լոռեմ, իպսում, դոլոռ, սիթ, ամեթ, ,, եխ, իուս,...  armenian\n",
       "1089  (թե, գռաեծե, վեռեառ, գռաեծիս, քուի, ,, դեբեթ, ...  armenian\n",
       "1090  (լոռեմ, իպսում, դոլոռ, սիթ, ամեթ, ,, նո, վել, ...  armenian"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armenian['language'] = ['armenian'] * len(armenian)\n",
    "armenian.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ae5209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "georgian = pd.DataFrame(list(zip(georgian_sentences)), columns = ['text'])\n",
    "#georgian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a00e3b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>(ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, ალთერა, ინ...</td>\n",
       "      <td>georgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>(ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, ესთ, ეუ, დ...</td>\n",
       "      <td>georgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>(თოთა, გრაეცი, ერრორიბუს, ცუ, მელ., ეუ, ეხფეთე...</td>\n",
       "      <td>georgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>(ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, თორყუათოს,...</td>\n",
       "      <td>georgian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>(ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, ფერ, სუას,...</td>\n",
       "      <td>georgian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  language\n",
       "1020  (ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, ალთერა, ინ...  georgian\n",
       "1021  (ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, ესთ, ეუ, დ...  georgian\n",
       "1022  (თოთა, გრაეცი, ერრორიბუს, ცუ, მელ., ეუ, ეხფეთე...  georgian\n",
       "1023  (ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, თორყუათოს,...  georgian\n",
       "1024  (ლორემ, იფსუმ, დოლორ, სით, ამეთ, ,, ფერ, სუას,...  georgian"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "georgian['language'] = ['georgian'] * len(georgian)\n",
    "georgian.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fb2c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latin = pd.DataFrame(list(zip(latin_sentences)), columns = ['text'])\n",
    "#latin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ee6aed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>(Donec, congue, odio, id, diam, imperdiet, ,, ...</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>(Cras, elementum, leo, id, ipsum, dictum, lobo...</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>(Donec, vel, aliquet, libero, .)</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>(Etiam, eu, lectus, mattis, ,, consequat, tell...</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>(In, fringilla, pharetra, nulla, id, molestie, .)</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "1033  (Donec, congue, odio, id, diam, imperdiet, ,, ...    latin\n",
       "1034  (Cras, elementum, leo, id, ipsum, dictum, lobo...    latin\n",
       "1035                   (Donec, vel, aliquet, libero, .)    latin\n",
       "1036  (Etiam, eu, lectus, mattis, ,, consequat, tell...    latin\n",
       "1037  (In, fringilla, pharetra, nulla, id, molestie, .)    latin"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin['language'] = ['latin'] * len(latin)\n",
    "latin.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f696a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "swedish = pd.DataFrame(swedish_sentences, columns = ['text'])\n",
    "#swedish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22d0f9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Annan hela vad jäst strand brunsås det rot doc...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Redan år flera strand bra rännil dimmhöljd vid...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Del denna träutensilierna vad rännil dock fler...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Trevnadens både björnbär hans där som tre denn...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Sorgliga tiden ta om, att.</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "999   Annan hela vad jäst strand brunsås det rot doc...  swedish\n",
       "1000  Redan år flera strand bra rännil dimmhöljd vid...  swedish\n",
       "1001  Del denna träutensilierna vad rännil dock fler...  swedish\n",
       "1002  Trevnadens både björnbär hans där som tre denn...  swedish\n",
       "1003                         Sorgliga tiden ta om, att.  swedish"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swedish['language'] = ['swedish'] * len(swedish)\n",
    "swedish.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ff554",
   "metadata": {},
   "source": [
    "#### Merging All the DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf940db",
   "metadata": {},
   "source": [
    "Now that we have gathered all the languages and put them into each individual DataFrames, we're going to combine all into one single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "565f1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_data = pd.concat([english, spanish, french, german, italian, dutch, portuguese, chinese, japanese, korean, russian, hebrew, arabic, hindi, greek, armenian, georgian, latin, swedish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "365e83d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We counted nouns both singular and plural, whe...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She now has two additional programs, a talk sh...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese travelers are ignoring    dressing cus...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Television\\r\\nSaturday Night Live Faces Off Ag...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mallory Ortberg, Dear Prudence columnist, Slat...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language\n",
       "0  We counted nouns both singular and plural, whe...  english\n",
       "1  She now has two additional programs, a talk sh...  english\n",
       "2  Chinese travelers are ignoring    dressing cus...  english\n",
       "3  Television\\r\\nSaturday Night Live Faces Off Ag...  english\n",
       "4  Mallory Ortberg, Dear Prudence columnist, Slat...  english"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language_data.head(10000)\n",
    "language_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5cd94877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Annan hela vad jäst strand brunsås det rot doc...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Redan år flera strand bra rännil dimmhöljd vid...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Del denna träutensilierna vad rännil dock fler...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Trevnadens både björnbär hans där som tre denn...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Sorgliga tiden ta om, att.</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text language\n",
       "999   Annan hela vad jäst strand brunsås det rot doc...  swedish\n",
       "1000  Redan år flera strand bra rännil dimmhöljd vid...  swedish\n",
       "1001  Del denna träutensilierna vad rännil dock fler...  swedish\n",
       "1002  Trevnadens både björnbär hans där som tre denn...  swedish\n",
       "1003                         Sorgliga tiden ta om, att.  swedish"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language_data.tail(10000)\n",
    "language_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71387436",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Part 3: Convert DataFrame to `.csv` File\n",
    "\n",
    "We want to convert it to a `.csv` because it takes so long to run the code above every single time, we want a more permanent solution we can pull the data from. By doing this, the sentences won't randomize every time as well.\n",
    "\n",
    "\n",
    "From now on, we'll be using the data from the `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "23bfdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_data_csv = language_data.to_csv(\"language_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822ccab",
   "metadata": {},
   "source": [
    "To make sure this has worked, we're going to call the `.csv` file that's been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "b3438286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We counted nouns both singular and plural, whe...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She now has two additional programs, a talk sh...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese travelers are ignoring    dressing cus...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Television\\r\\nSaturday Night Live Faces Off Ag...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mallory Ortberg, Dear Prudence columnist, Slat...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language\n",
       "0  We counted nouns both singular and plural, whe...  english\n",
       "1  She now has two additional programs, a talk sh...  english\n",
       "2  Chinese travelers are ignoring    dressing cus...  english\n",
       "3  Television\\r\\nSaturday Night Live Faces Off Ag...  english\n",
       "4  Mallory Ortberg, Dear Prudence columnist, Slat...  english"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_language_data = pd.read_csv('language_data.csv')\n",
    "#new_language_data.head(10000)\n",
    "new_language_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d45c5bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19541</th>\n",
       "      <td>Annan hela vad jäst strand brunsås det rot doc...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19542</th>\n",
       "      <td>Redan år flera strand bra rännil dimmhöljd vid...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19543</th>\n",
       "      <td>Del denna träutensilierna vad rännil dock fler...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19544</th>\n",
       "      <td>Trevnadens både björnbär hans där som tre denn...</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19545</th>\n",
       "      <td>Sorgliga tiden ta om, att.</td>\n",
       "      <td>swedish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text language\n",
       "19541  Annan hela vad jäst strand brunsås det rot doc...  swedish\n",
       "19542  Redan år flera strand bra rännil dimmhöljd vid...  swedish\n",
       "19543  Del denna träutensilierna vad rännil dock fler...  swedish\n",
       "19544  Trevnadens både björnbär hans där som tre denn...  swedish\n",
       "19545                         Sorgliga tiden ta om, att.  swedish"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_language_data.tail(10000)\n",
    "new_language_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b293ace",
   "metadata": {},
   "source": [
    "Now we'll want to check to see if there's any missing values; if there are, we need to remove them or the model won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "5173cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_language_data = new_language_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "039d8f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_language_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "97ed9e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "russian       1177\n",
       "chinese       1099\n",
       "armenian      1091\n",
       "english       1087\n",
       "arabic        1038\n",
       "latin         1038\n",
       "korean        1028\n",
       "georgian      1025\n",
       "hindi         1018\n",
       "swedish       1004\n",
       "hebrew        1002\n",
       "greek         1001\n",
       "german        1000\n",
       "french        1000\n",
       "japanese      1000\n",
       "portuguese    1000\n",
       "dutch         1000\n",
       "italian       1000\n",
       "spanish       1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_language_data['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9bf79",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Part 4: Creating the Model\n",
    "\n",
    "Now that the data is been cleaned, we can now go ahead and split the data set into training and test sets. We will need to fit and transform the data into a format `scikit-learn` can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "92d81d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_language_data['text']\n",
    "y = new_language_data['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "fe8da761",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y) #this will return the language rather than a number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497f1a8",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "43c647b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "8a847045",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "1a2371d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "d795355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944416114227435"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417149e",
   "metadata": {},
   "source": [
    "#### Language Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fbc422",
   "metadata": {},
   "source": [
    "Since the `.score` is rated as 94.44%, we should be able to get a pretty accurate result when we predict the language the is entered. We are going to test this model using 5 unknown languages.\n",
    "\n",
    "*Note: These sentences were created by writing in English, then using Google Translate to get the sentences in these languages. Therefore the sentences might not be gramatically accurate.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "3801f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#language_one = 'I like to eat potatoes for dinner.'\n",
    "#language_two = 'Estudié durante cuatro horas ayer por la tarde.'\n",
    "#language_three = \"J'aime manger des oranges tous les jours à l'hôtel.\"\n",
    "#language_four = 'Hast du letzte Nacht genug geschlafen?'\n",
    "#language_five = 'Ti piace mangiare il pane con la marmellata.'\n",
    "#language_six = 'Ik zag het vliegtuig in de nachtelijke hemel.'\n",
    "#language_seven = 'Eu gosto de caminhar uma vez por mês.'\n",
    "#language_eight = '我喜欢放学后学习数学'\n",
    "#language_nine = '今日は自転車で通勤しました'\n",
    "#language_ten = '내일 시험에 어려운 문제가 있을 것이다.'\n",
    "#language_eleven = 'Я сегодня ездил на автобусе в магазин'\n",
    "#language_twelve = 'כבר מאוחר מדי הגיע הזמן ללכת לישון'\n",
    "#language_thirteen = 'ذهبت مع صديقي في وقت سابق لشراء المزيد من الملابس'\n",
    "#language_fourteen = 'क्या आपने नई किताब के बारे में सुना है जो आ रही है'\n",
    "#language_fifteen = 'Έχουμε σχέδια να ταξιδέψουμε στα βουνά τον επόμενο μήνα'\n",
    "#language_sixteen = 'Ես սիրում եմ շոյել շանը'\n",
    "#language_seventeen = 'მაგიდაზე არის ფურცელი, რომელზეც ჩანაწერებია'\n",
    "#language_eighteen = 'Vide ne obliviscaris vigiliam domi relinquere'\n",
    "#language_nineteen = 'Den här staden har så många berg, grönskan är vacker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "2b0f9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_one = \"J'aime manger des oranges tous les jours à l'hôtel.\"\n",
    "language_two = '내일 시험에 어려운 문제가 있을 것이다.'\n",
    "language_three = 'Ik zag het vliegtuig in de nachtelijke hemel.'\n",
    "language_four = 'Я сегодня ездил на автобусе в магазин'\n",
    "language_five = 'Eu gosto de caminhar uma vez por mês.'\n",
    "language_six = 'ذهبت مع صديقي في وقت سابق لشراء المزيد من الملابس'\n",
    "language_seven = 'Den här staden har så många berg, grönskan är vacker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "1251e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(language):\n",
    "    x = vectorizer.transform([language]).toarray()\n",
    "    lang = model.predict(x)\n",
    "    lang = encoder.inverse_transform(lang) #finds the language corresponding to the predicted value\n",
    "    return lang[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "e5014d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "9def73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korean\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "f7953904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dutch\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_three)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "b58ecc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russian\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_four))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "9f4a93c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portuguese\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "971fe08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_six))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "9162e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swedish\n"
     ]
    }
   ],
   "source": [
    "print(predict(language_seven))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224803e0",
   "metadata": {},
   "source": [
    "Based off our language detection model, it got all of our languages correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dff61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
